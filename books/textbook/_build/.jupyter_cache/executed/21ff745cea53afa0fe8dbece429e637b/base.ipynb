{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2dd0c2e-99c9-47fc-a1c9-a89ea2b48498",
   "metadata": {
    "tags": [
     "remove-cell",
     "remove-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%run -i ../python/common.py\n",
    "closeAllOpenTtySessions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4a83cf-b1ac-4c98-a4cd-a97588690400",
   "metadata": {
    "tags": [
     "output_scroll",
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09c897ca732452e8e73af73227fa56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bash = BashSession()\n",
    "bash.run(\"man sched\", height='2in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da540d-8fa4-4fb3-9ca4-01a358cac9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "21c52d4d466045eea7bd242b070a7b99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": "1px solid black",
       "border_left": "1px solid black",
       "border_right": "1px solid black",
       "border_top": "1px solid black",
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": "2in",
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e09c897ca732452e8e73af73227fa56b": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_21c52d4d466045eea7bd242b070a7b99",
       "msg_id": "",
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": "$ man sched\r\n\u001b[4msched\u001b[24m(7)               Miscellaneous Information Manual               \u001b[4msched\u001b[24m(7)\r\n\r\n\u001b[1mNAME\u001b[0m\r\n       sched - overview of CPU scheduling\r\n\r\n\u001b[1mDESCRIPTION\u001b[0m\r\n       Since  Linux 2.6.23, the default scheduler is CFS, the \"Completely Fair\r\n       Scheduler\".  The CFS scheduler replaced the earlier \"O(1)\" scheduler.\r\n\r\n   \u001b[1mAPI summary\u001b[0m\r\n       Linux provides the following  system  calls  for  controlling  the  CPU\r\n       scheduling  behavior,  policy, and priority of processes (or, more pre‐\r\n       cisely, threads).\r\n\r\n       \u001b[1mnice\u001b[22m(2)\r\n              Set a new nice value for the calling thread, and return the  new\r\n              nice value.\r\n\r\n       \u001b[1mgetpriority\u001b[22m(2)\r\n              Return  the  nice value of a thread, a process group, or the set\r\n              of threads owned by a specified user.\r\n\r\n       \u001b[1msetpriority\u001b[22m(2)\r\n              Set the nice value of a thread, a process group, or the  set  of\r\n              threads owned by a specified user.\r\n\r\n       \u001b[1msched_setscheduler\u001b[22m(2)\r\n              Set the scheduling policy and parameters of a specified thread.\r\n\r\n       \u001b[1msched_getscheduler\u001b[22m(2)\r\n              Return the scheduling policy of a specified thread.\r\n\r\n       \u001b[1msched_setparam\u001b[22m(2)\r\n              Set the scheduling parameters of a specified thread.\r\n\r\n       \u001b[1msched_getparam\u001b[22m(2)\r\n              Fetch the scheduling parameters of a specified thread.\r\n\r\n       \u001b[1msched_get_priority_max\u001b[22m(2)\r\n              Return  the maximum priority available in a specified scheduling\r\n              policy.\r\n\r\n       \u001b[1msched_get_priority_min\u001b[22m(2)\r\n              Return the minimum priority available in a specified  scheduling\r\n              policy.\r\n\r\n       \u001b[1msched_rr_get_interval\u001b[22m(2)\r\n              Fetch  the quantum used for threads that are scheduled under the\r\n              \"round-robin\" scheduling policy.\r\n\r\n       \u001b[1msched_yield\u001b[22m(2)\r\n              Cause the caller to relinquish  the  CPU,  so  that  some  other\r\n              thread be executed.\r\n\r\n       \u001b[1msched_setaffinity\u001b[22m(2)\r\n              (Linux-specific) Set the CPU affinity of a specified thread.\r\n\r\n       \u001b[1msched_getaffinity\u001b[22m(2)\r\n              (Linux-specific) Get the CPU affinity of a specified thread.\r\n\r\n       \u001b[1msched_setattr\u001b[22m(2)\r\n              Set  the scheduling policy and parameters of a specified thread.\r\n              This (Linux-specific) system call provides  a  superset  of  the\r\n              functionality of \u001b[1msched_setscheduler\u001b[22m(2) and \u001b[1msched_setparam\u001b[22m(2).\r\n\r\n       \u001b[1msched_getattr\u001b[22m(2)\r\n              Fetch  the  scheduling  policy  and  parameters  of  a specified\r\n              thread.  This (Linux-specific) system call provides  a  superset\r\n              of  the  functionality  of  \u001b[1msched_getscheduler\u001b[22m(2) and \u001b[1msched_get‐\u001b[0m\r\n              \u001b[1mparam\u001b[22m(2).\r\n\r\n   \u001b[1mScheduling policies\u001b[0m\r\n       The scheduler is the  kernel  component  that  decides  which  runnable\r\n       thread will be executed by the CPU next.  Each thread has an associated\r\n       scheduling  policy  and  a  \u001b[4mstatic\u001b[24m scheduling priority, \u001b[4msched_priority\u001b[24m.\r\n       The scheduler makes its decisions based on knowledge of the  scheduling\r\n       policy and static priority of all threads on the system.\r\n\r\n       For  threads  scheduled  under  one  of  the normal scheduling policies\r\n       (\u001b[1mSCHED_OTHER\u001b[22m, \u001b[1mSCHED_IDLE\u001b[22m, \u001b[1mSCHED_BATCH\u001b[22m), \u001b[4msched_priority\u001b[24m is not  used  in\r\n       scheduling decisions (it must be specified as 0).\r\n\r\n       Processes  scheduled  under  one of the real-time policies (\u001b[1mSCHED_FIFO\u001b[22m,\r\n       \u001b[1mSCHED_RR\u001b[22m) have a \u001b[4msched_priority\u001b[24m value  in  the  range  1  (low)  to  99\r\n       (high).   (As  the  numbers imply, real-time threads always have higher\r\n       priority than normal threads.)  Note well: POSIX.1 requires  an  imple‐\r\n       mentation to support only a minimum 32 distinct priority levels for the\r\n       real-time   policies,  and  some  systems  supply  just  this  minimum.\r\n       Portable   programs   should    use    \u001b[1msched_get_priority_min\u001b[22m(2)    and\r\n       \u001b[1msched_get_priority_max\u001b[22m(2) to find the range of priorities supported for\r\n       a particular policy.\r\n\r\n       Conceptually,  the  scheduler  maintains a list of runnable threads for\r\n       each possible \u001b[4msched_priority\u001b[24m value.  In order to determine which thread\r\n       runs next, the scheduler looks for the nonempty list with  the  highest\r\n       static priority and selects the thread at the head of this list.\r\n\r\n       A  thread's scheduling policy determines where it will be inserted into\r\n       the list of threads with equal static priority and how it will move in‐\r\n       side this list.\r\n\r\n       All scheduling is preemptive: if a thread with a higher static priority\r\n       becomes ready to run, the currently running thread  will  be  preempted\r\n       and  returned  to  the  wait  list  for its static priority level.  The\r\n       scheduling policy determines the  ordering  only  within  the  list  of\r\n       runnable threads with equal static priority.\r\n\r\n   \u001b[1mSCHED_FIFO: First in-first out scheduling\u001b[0m\r\n       \u001b[1mSCHED_FIFO \u001b[22mcan be used only with static priorities higher than 0, which\r\n       means  that  when  a \u001b[1mSCHED_FIFO \u001b[22mthread becomes runnable, it will always\r\n       immediately preempt any currently running \u001b[1mSCHED_OTHER\u001b[22m, \u001b[1mSCHED_BATCH\u001b[22m,  or\r\n       \u001b[1mSCHED_IDLE \u001b[22mthread.  \u001b[1mSCHED_FIFO \u001b[22mis a simple scheduling algorithm without\r\n       time  slicing.   For threads scheduled under the \u001b[1mSCHED_FIFO \u001b[22mpolicy, the\r\n       following rules apply:\r\n\r\n       •  A running \u001b[1mSCHED_FIFO \u001b[22mthread  that  has  been  preempted  by  another\r\n          thread  of higher priority will stay at the head of the list for its\r\n          priority and will resume execution as soon as all threads of  higher\r\n          priority are blocked again.\r\n\r\n       •  When  a  blocked  \u001b[1mSCHED_FIFO \u001b[22mthread becomes runnable, it will be in‐\r\n          serted at the end of the list for its priority.\r\n\r\n       •  If a call  to  \u001b[1msched_setscheduler\u001b[22m(2),  \u001b[1msched_setparam\u001b[22m(2),  \u001b[1msched_se‐\u001b[0m\r\n          \u001b[1mtattr\u001b[22m(2),   \u001b[1mpthread_setschedparam\u001b[22m(3),   or   \u001b[1mpthread_setschedprio\u001b[22m(3)\r\n          changes the priority of the running or  runnable  \u001b[1mSCHED_FIFO  \u001b[22mthread\r\n          identified  by  \u001b[4mpid\u001b[24m  the effect on the thread's position in the list\r\n          depends on the direction of the change to the thread's priority:\r\n\r\n          (a)  If the thread's priority is raised, it is placed at the end  of\r\n               the  list  for its new priority.  As a consequence, it may pre‐\r\n               empt a currently running thread with the same priority.\r\n\r\n          (b)  If the thread's priority is unchanged, its position in the  run\r\n               list is unchanged.\r\n\r\n          (c)  If  the thread's priority is lowered, it is placed at the front\r\n               of the list for its new priority.\r\n\r\n          According to POSIX.1-2008, changes to a thread's priority  (or  pol‐\r\n          icy)  using  any mechanism other than \u001b[1mpthread_setschedprio\u001b[22m(3) should\r\n          result in the thread being placed at the end of  the  list  for  its\r\n          priority.\r\n\r\n       •  A thread calling \u001b[1msched_yield\u001b[22m(2) will be put at the end of the list.\r\n\r\n       No  other events will move a thread scheduled under the \u001b[1mSCHED_FIFO \u001b[22mpol‐\r\n       icy in the wait list of runnable threads with equal static priority.\r\n\r\n       A \u001b[1mSCHED_FIFO \u001b[22mthread runs until either it is blocked by an I/O  request,\r\n       it   is   preempted   by   a   higher  priority  thread,  or  it  calls\r\n       \u001b[1msched_yield\u001b[22m(2).\r\n\r\n   \u001b[1mSCHED_RR: Round-robin scheduling\u001b[0m\r\n       \u001b[1mSCHED_RR \u001b[22mis a simple enhancement of \u001b[1mSCHED_FIFO\u001b[22m.   Everything  described\r\n       above  for \u001b[1mSCHED_FIFO \u001b[22malso applies to \u001b[1mSCHED_RR\u001b[22m, except that each thread\r\n       is allowed to run only for a  maximum  time  quantum.   If  a  \u001b[1mSCHED_RR\u001b[0m\r\n       thread  has  been running for a time period equal to or longer than the\r\n       time quantum, it will be put at the end of the list for  its  priority.\r\n       A  \u001b[1mSCHED_RR  \u001b[22mthread that has been preempted by a higher priority thread\r\n       and subsequently resumes execution as a running  thread  will  complete\r\n       the  unexpired  portion of its round-robin time quantum.  The length of\r\n       the time quantum can be retrieved using \u001b[1msched_rr_get_interval\u001b[22m(2).\r\n\r\n   \u001b[1mSCHED_DEADLINE: Sporadic task model deadline scheduling\u001b[0m\r\n       Since  Linux  3.14,  Linux  provides  a  deadline   scheduling   policy\r\n       (\u001b[1mSCHED_DEADLINE\u001b[22m).   This  policy  is  currently  implemented using GEDF\r\n       (Global Earliest Deadline First)  in  conjunction  with  CBS  (Constant\r\n       Bandwidth Server).  To set and fetch this policy and associated attrib‐\r\n       utes,   one   must   use   the   Linux-specific   \u001b[1msched_setattr\u001b[22m(2)  and\r\n       \u001b[1msched_getattr\u001b[22m(2) system calls.\r\n\r\n       A sporadic task is one that has a sequence of jobs, where each  job  is\r\n       activated  at most once per period.  Each job also has a \u001b[4mrelative\u001b[24m \u001b[4mdead‐\u001b[0m\r\n       \u001b[4mline\u001b[24m, before which it should finish execution, and a \u001b[4mcomputation\u001b[24m  \u001b[4mtime\u001b[24m,\r\n       which is the CPU time necessary for executing the job.  The moment when\r\n       a  task wakes up because a new job has to be executed is called the \u001b[4mar‐\u001b[0m\r\n       \u001b[4mrival\u001b[24m \u001b[4mtime\u001b[24m (also referred to as the request time or release time).  The\r\n       \u001b[4mstart\u001b[24m \u001b[4mtime\u001b[24m is the time at which a task starts its execution.   The  \u001b[4mab‐\u001b[0m\r\n       \u001b[4msolute\u001b[24m \u001b[4mdeadline\u001b[24m is thus obtained by adding the relative deadline to the\r\n       arrival time.\r\n\r\n       The following diagram clarifies these terms:\r\n\r\n           arrival/wakeup                    absolute deadline\r\n                |    start time                    |\r\n                |        |                         |\r\n                v        v                         v\r\n           -----x--------xooooooooooooooooo--------x--------x---\r\n                         |<- comp. time ->|\r\n                |<------- relative deadline ------>|\r\n                |<-------------- period ------------------->|\r\n\r\n       When  setting  a  \u001b[1mSCHED_DEADLINE  \u001b[22mpolicy  for  a thread using \u001b[1msched_se‐\u001b[0m\r\n       \u001b[1mtattr\u001b[22m(2), one can specify three parameters: \u001b[4mRuntime\u001b[24m, \u001b[4mDeadline\u001b[24m, and  \u001b[4mPe‐\u001b[0m\r\n       \u001b[4mriod\u001b[24m.   These parameters do not necessarily correspond to the aforemen‐\r\n       tioned terms: usual practice is to set Runtime to something bigger than\r\n       the average computation time (or worst-case  execution  time  for  hard\r\n       real-time  tasks), Deadline to the relative deadline, and Period to the\r\n       period of the task.  Thus, for \u001b[1mSCHED_DEADLINE \u001b[22mscheduling, we have:\r\n\r\n           arrival/wakeup                    absolute deadline\r\n                |    start time                    |\r\n                |        |                         |\r\n                v        v                         v\r\n           -----x--------xooooooooooooooooo--------x--------x---\r\n                         |<-- Runtime ------->|\r\n                |<----------- Deadline ----------->|\r\n                |<-------------- Period ------------------->|\r\n\r\n       The three deadline-scheduling parameters correspond to  the  \u001b[4msched_run‐\u001b[0m\r\n       \u001b[4mtime\u001b[24m,  \u001b[4msched_deadline\u001b[24m, and \u001b[4msched_period\u001b[24m fields of the \u001b[4msched_attr\u001b[24m struc‐\r\n       ture; see \u001b[1msched_setattr\u001b[22m(2).  These fields express  values  in  nanosec‐\r\n       onds.   If  \u001b[4msched_period\u001b[24m is specified as 0, then it is made the same as\r\n       \u001b[4msched_deadline\u001b[24m.\r\n\r\n       The kernel requires that:\r\n\r\n           sched_runtime <= sched_deadline <= sched_period\r\n\r\n       In addition, under the current implementation,  all  of  the  parameter\r\n       values must be at least 1024 (i.e., just over one microsecond, which is\r\n       the  resolution  of the implementation), and less than 2^63.  If any of\r\n       these checks fails, \u001b[1msched_setattr\u001b[22m(2) fails with the error \u001b[1mEINVAL\u001b[22m.\r\n\r\n       The  CBS  guarantees  non-interference  between  tasks,  by  throttling\r\n       threads that attempt to over-run their specified Runtime.\r\n\r\n       To ensure deadline scheduling guarantees, the kernel must prevent situ‐\r\n       ations where the set of \u001b[1mSCHED_DEADLINE \u001b[22mthreads is not feasible (schedu‐\r\n       lable)  within  the given constraints.  The kernel thus performs an ad‐\r\n       mittance test when setting or changing \u001b[1mSCHED_DEADLINE  \u001b[22mpolicy  and  at‐\r\n       tributes.   This admission test calculates whether the change is feasi‐\r\n       ble; if it is not, \u001b[1msched_setattr\u001b[22m(2) fails with the error \u001b[1mEBUSY\u001b[22m.\r\n\r\n       For example, it is required (but not necessarily  sufficient)  for  the\r\n       total  utilization to be less than or equal to the total number of CPUs\r\n       available, where, since each thread can maximally run for  Runtime  per\r\n       Period, that thread's utilization is its Runtime divided by its Period.\r\n\r\n       In  order  to fulfill the guarantees that are made when a thread is ad‐\r\n       mitted to the \u001b[1mSCHED_DEADLINE \u001b[22mpolicy,  \u001b[1mSCHED_DEADLINE  \u001b[22mthreads  are  the\r\n       highest  priority  (user  controllable)  threads  in the system; if any\r\n       \u001b[1mSCHED_DEADLINE \u001b[22mthread is runnable, it will preempt any thread scheduled\r\n       under one of the other policies.\r\n\r\n       A call to \u001b[1mfork\u001b[22m(2) by a thread scheduled under the \u001b[1mSCHED_DEADLINE \u001b[22mpolicy\r\n       fails with the error \u001b[1mEAGAIN\u001b[22m, unless the thread  has  its  reset-on-fork\r\n       flag set (see below).\r\n\r\n       A  \u001b[1mSCHED_DEADLINE  \u001b[22mthread that calls \u001b[1msched_yield\u001b[22m(2) will yield the cur‐\r\n       rent job and wait for a new period to begin.\r\n\r\n   \u001b[1mSCHED_OTHER: Default Linux time-sharing scheduling\u001b[0m\r\n       \u001b[1mSCHED_OTHER \u001b[22mcan be used at only static priority 0 (i.e., threads  under\r\n       real-time  policies  always  have priority over \u001b[1mSCHED_OTHER \u001b[22mprocesses).\r\n       \u001b[1mSCHED_OTHER \u001b[22mis the standard Linux time-sharing scheduler  that  is  in‐\r\n       tended for all threads that do not require the special real-time mecha‐\r\n       nisms.\r\n\r\n       The  thread to run is chosen from the static priority 0 list based on a\r\n       \u001b[4mdynamic\u001b[24m priority that is determined only inside this list.  The dynamic\r\n       priority is based on the nice value (see below) and  is  increased  for\r\n       each  time quantum the thread is ready to run, but denied to run by the\r\n       scheduler.  This ensures fair progress among all \u001b[1mSCHED_OTHER \u001b[22mthreads.\r\n\r\n       In the Linux kernel source code, the  \u001b[1mSCHED_OTHER  \u001b[22mpolicy  is  actually\r\n       named \u001b[1mSCHED_NORMAL\u001b[22m.\r\n\r\n   \u001b[1mThe nice value\u001b[0m\r\n       The  nice  value  is an attribute that can be used to influence the CPU\r\n       scheduler to favor or disfavor a process in scheduling  decisions.   It\r\n       affects  the  scheduling  of  \u001b[1mSCHED_OTHER  \u001b[22mand  \u001b[1mSCHED_BATCH \u001b[22m(see below)\r\n       processes.  The nice value can be  modified  using  \u001b[1mnice\u001b[22m(2),  \u001b[1msetprior‐\u001b[0m\r\n       \u001b[1mity\u001b[22m(2), or \u001b[1msched_setattr\u001b[22m(2).\r\n\r\n       According  to  POSIX.1, the nice value is a per-process attribute; that\r\n       is, the threads in a process should share a nice  value.   However,  on\r\n       Linux,  the  nice value is a per-thread attribute: different threads in\r\n       the same process may have different nice values.\r\n\r\n       The range of the nice value varies  across  UNIX  systems.   On  modern\r\n       Linux, the range is -20 (high priority) to +19 (low priority).  On some\r\n       other  systems, the range is -20..20.  Very early Linux kernels (before\r\n       Linux 2.0) had the range -infinity..15.\r\n\r\n       The degree to which the nice value affects the relative  scheduling  of\r\n       \u001b[1mSCHED_OTHER  \u001b[22mprocesses  likewise  varies across UNIX systems and across\r\n       Linux kernel versions.\r\n\r\n       With the advent of the CFS scheduler in Linux 2.6.23, Linux adopted  an\r\n       algorithm  that  causes  relative  differences in nice values to have a\r\n       much stronger effect.  In the current implementation, each unit of dif‐\r\n       ference in the nice values of two processes results in a factor of 1.25\r\n       in the degree  to  which  the  scheduler  favors  the  higher  priority\r\n       process.   This causes very low nice values (+19) to truly provide lit‐\r\n       tle CPU to a process whenever there is any other higher  priority  load\r\n       on the system, and makes high nice values (-20) deliver most of the CPU\r\n       to applications that require it (e.g., some audio applications).\r\n\r\n       On  Linux, the \u001b[1mRLIMIT_NICE \u001b[22mresource limit can be used to define a limit\r\n       to which an unprivileged process's nice value can be raised; see  \u001b[1msetr‐\u001b[0m\r\n       \u001b[1mlimit\u001b[22m(2) for details.\r\n\r\n       For further details on the nice value, see the subsections on the auto‐\r\n       group feature and group scheduling, below.\r\n\r\n   \u001b[1mSCHED_BATCH: Scheduling batch processes\u001b[0m\r\n       (Since  Linux 2.6.16.)  \u001b[1mSCHED_BATCH \u001b[22mcan be used only at static priority\r\n       0.  This policy is similar to \u001b[1mSCHED_OTHER  \u001b[22min  that  it  schedules  the\r\n       thread  according  to  its  dynamic priority (based on the nice value).\r\n       The difference is that this policy will cause the scheduler  to  always\r\n       assume  that  the thread is CPU-intensive.  Consequently, the scheduler\r\n       will apply a small scheduling penalty with respect to wakeup  behavior,\r\n       so that this thread is mildly disfavored in scheduling decisions.\r\n\r\n       This policy is useful for workloads that are noninteractive, but do not\r\n       want to lower their nice value, and for workloads that want a determin‐\r\n       istic scheduling policy without interactivity causing extra preemptions\r\n       (between the workload's tasks).\r\n\r\n   \u001b[1mSCHED_IDLE: Scheduling very low priority jobs\u001b[0m\r\n       (Since  Linux  2.6.23.)  \u001b[1mSCHED_IDLE \u001b[22mcan be used only at static priority\r\n       0; the process nice value has no influence for this policy.\r\n\r\n       This policy is intended for running  jobs  at  extremely  low  priority\r\n       (lower  even  than a +19 nice value with the \u001b[1mSCHED_OTHER \u001b[22mor \u001b[1mSCHED_BATCH\u001b[0m\r\n       policies).\r\n\r\n   \u001b[1mResetting scheduling policy for child processes\u001b[0m\r\n       Each thread has a reset-on-fork scheduling flag.   When  this  flag  is\r\n       set,  children  created by \u001b[1mfork\u001b[22m(2) do not inherit privileged scheduling\r\n       policies.  The reset-on-fork flag can be set by either:\r\n\r\n       •  ORing the \u001b[1mSCHED_RESET_ON_FORK \u001b[22mflag into  the  \u001b[4mpolicy\u001b[24m  argument  when\r\n          calling \u001b[1msched_setscheduler\u001b[22m(2) (since Linux 2.6.32); or\r\n\r\n       •  specifying  the  \u001b[1mSCHED_FLAG_RESET_ON_FORK  \u001b[22mflag  in \u001b[4mattr.sched_flags\u001b[0m\r\n          when calling \u001b[1msched_setattr\u001b[22m(2).\r\n\r\n       Note that the constants used with these two APIs have different  names.\r\n       The  state of the reset-on-fork flag can analogously be retrieved using\r\n       \u001b[1msched_getscheduler\u001b[22m(2) and \u001b[1msched_getattr\u001b[22m(2).\r\n\r\n       The reset-on-fork feature is intended for media-playback  applications,\r\n       and  can  be used to prevent applications evading the \u001b[1mRLIMIT_RTTIME \u001b[22mre‐\r\n       source limit (see \u001b[1mgetrlimit\u001b[22m(2)) by creating multiple child processes.\r\n\r\n       More precisely, if the reset-on-fork flag is set, the  following  rules\r\n       apply for subsequently created children:\r\n\r\n       •  If  the  calling  thread  has  a  scheduling policy of \u001b[1mSCHED_FIFO \u001b[22mor\r\n          \u001b[1mSCHED_RR\u001b[22m, the policy is reset to \u001b[1mSCHED_OTHER \u001b[22min child processes.\r\n\r\n       •  If the calling process has a negative nice value, the nice value  is\r\n          reset to zero in child processes.\r\n\r\n       After  the reset-on-fork flag has been enabled, it can be reset only if\r\n       the thread has the \u001b[1mCAP_SYS_NICE \u001b[22mcapability.  This flag is  disabled  in\r\n       child processes created by \u001b[1mfork\u001b[22m(2).\r\n\r\n   \u001b[1mPrivileges and resource limits\u001b[0m\r\n       Before  Linux  2.6.12, only privileged (\u001b[1mCAP_SYS_NICE\u001b[22m) threads can set a\r\n       nonzero static priority (i.e., set a real-time scheduling policy).  The\r\n       only change that  an  unprivileged  thread  can  make  is  to  set  the\r\n       \u001b[1mSCHED_OTHER  \u001b[22mpolicy, and this can be done only if the effective user ID\r\n       of the caller matches the real or  effective  user  ID  of  the  target\r\n       thread  (i.e.,  the  thread  specified  by  \u001b[4mpid\u001b[24m)  whose policy is being\r\n       changed.\r\n\r\n       A thread must be privileged (\u001b[1mCAP_SYS_NICE\u001b[22m) in order to set or modify  a\r\n       \u001b[1mSCHED_DEADLINE \u001b[22mpolicy.\r\n\r\n       Since  Linux 2.6.12, the \u001b[1mRLIMIT_RTPRIO \u001b[22mresource limit defines a ceiling\r\n       on an unprivileged  thread's  static  priority  for  the  \u001b[1mSCHED_RR  \u001b[22mand\r\n       \u001b[1mSCHED_FIFO \u001b[22mpolicies.  The rules for changing scheduling policy and pri‐\r\n       ority are as follows:\r\n\r\n       •  If  an  unprivileged  thread has a nonzero \u001b[1mRLIMIT_RTPRIO \u001b[22msoft limit,\r\n          then it can change its scheduling policy and  priority,  subject  to\r\n          the  restriction  that  the priority cannot be set to a value higher\r\n          than the maximum of its current priority and its \u001b[1mRLIMIT_RTPRIO  \u001b[22msoft\r\n          limit.\r\n\r\n       •  If  the  \u001b[1mRLIMIT_RTPRIO  \u001b[22msoft  limit  is  0,  then the only permitted\r\n          changes are to lower the priority, or to switch to  a  non-real-time\r\n          policy.\r\n\r\n       •  Subject to the same rules, another unprivileged thread can also make\r\n          these changes, as long as the effective user ID of the thread making\r\n          the  change  matches  the  real  or  effective user ID of the target\r\n          thread.\r\n\r\n       •  Special rules apply for the \u001b[1mSCHED_IDLE \u001b[22mpolicy.  Before Linux 2.6.39,\r\n          an unprivileged thread operating under this policy cannot change its\r\n          policy, regardless of the value of its \u001b[1mRLIMIT_RTPRIO \u001b[22mresource limit.\r\n          Since Linux 2.6.39, an unprivileged thread can switch to either  the\r\n          \u001b[1mSCHED_BATCH  \u001b[22mor  the  \u001b[1mSCHED_OTHER  \u001b[22mpolicy  so long as its nice value\r\n          falls within the range permitted by its \u001b[1mRLIMIT_NICE  \u001b[22mresource  limit\r\n          (see \u001b[1mgetrlimit\u001b[22m(2)).\r\n\r\n       Privileged  (\u001b[1mCAP_SYS_NICE\u001b[22m)  threads  ignore the \u001b[1mRLIMIT_RTPRIO \u001b[22mlimit; as\r\n       with older kernels, they can make arbitrary changes to scheduling  pol‐\r\n       icy   and  priority.   See  \u001b[1mgetrlimit\u001b[22m(2)  for  further  information  on\r\n       \u001b[1mRLIMIT_RTPRIO\u001b[22m.\r\n\r\n   \u001b[1mLimiting the CPU usage of real-time and deadline processes\u001b[0m\r\n       A nonblocking infinite loop in a thread scheduled under the \u001b[1mSCHED_FIFO\u001b[22m,\r\n       \u001b[1mSCHED_RR\u001b[22m, or \u001b[1mSCHED_DEADLINE \u001b[22mpolicy  can  potentially  block  all  other\r\n       threads  from accessing the CPU forever.  Before Linux 2.6.25, the only\r\n       way of preventing a runaway real-time process from freezing the  system\r\n       was  to  run  (at  the console) a shell scheduled under a higher static\r\n       priority than the tested application.  This allows an emergency kill of\r\n       tested real-time applications that do not block  or  terminate  as  ex‐\r\n       pected.\r\n\r\n       Since Linux 2.6.25, there are other techniques for dealing with runaway\r\n       real-time  and  deadline  processes.   One  of  these  is  to  use  the\r\n       \u001b[1mRLIMIT_RTTIME \u001b[22mresource limit to set a ceiling on the CPU  time  that  a\r\n       real-time process may consume.  See \u001b[1mgetrlimit\u001b[22m(2) for details.\r\n\r\n       Since  Linux  2.6.25,  Linux  also provides two \u001b[4m/proc\u001b[24m files that can be\r\n       used to reserve a certain amount of CPU time to be  used  by  non-real-\r\n       time  processes.   Reserving  CPU  time in this fashion allows some CPU\r\n       time to be allocated to (say) a root shell that can be used to  kill  a\r\n       runaway  process.  Both of these files specify time values in microsec‐\r\n       onds:\r\n\r\n       \u001b[4m/proc/sys/kernel/sched_rt_period_us\u001b[0m\r\n              This file specifies a scheduling period that  is  equivalent  to\r\n              100%  CPU bandwidth.  The value in this file can range from 1 to\r\n              \u001b[1mINT_MAX\u001b[22m, giving an operating range of 1 microsecond to around 35\r\n              minutes.  The default value in this file is  1,000,000  (1  sec‐\r\n              ond).\r\n\r\n       \u001b[4m/proc/sys/kernel/sched_rt_runtime_us\u001b[0m\r\n              The  value  in this file specifies how much of the \"period\" time\r\n              can be used by all real-time and deadline scheduled processes on\r\n              the system.  The value  in  this  file  can  range  from  -1  to\r\n              \u001b[1mINT_MAX\u001b[22m-1.  Specifying -1 makes the run time the same as the pe‐\r\n              riod;  that  is,  no  CPU  time  is  set aside for non-real-time\r\n              processes (which was the behavior before Linux 2.6.25).  The de‐\r\n              fault value in this file is 950,000 (0.95 seconds), meaning that\r\n              5% of the CPU time is reserved for processes that don't run  un‐\r\n              der a real-time or deadline scheduling policy.\r\n\r\n   \u001b[1mResponse time\u001b[0m\r\n       A  blocked  high priority thread waiting for I/O has a certain response\r\n       time before it is  scheduled  again.   The  device  driver  writer  can\r\n       greatly reduce this response time by using a \"slow interrupt\" interrupt\r\n       handler.\r\n\r\n   \u001b[1mMiscellaneous\u001b[0m\r\n       Child  processes  inherit the scheduling policy and parameters across a\r\n       \u001b[1mfork\u001b[22m(2).  The scheduling policy and parameters are preserved across \u001b[1mex‐\u001b[0m\r\n       \u001b[1mecve\u001b[22m(2).\r\n\r\n       Memory locking is usually needed for real-time processes to avoid  pag‐\r\n       ing delays; this can be done with \u001b[1mmlock\u001b[22m(2) or \u001b[1mmlockall\u001b[22m(2).\r\n\r\n   \u001b[1mThe autogroup feature\u001b[0m\r\n       Since Linux 2.6.38, the kernel provides a feature known as autogrouping\r\n       to improve interactive desktop performance in the face of multiprocess,\r\n       CPU-intensive  workloads  such  as building the Linux kernel with large\r\n       numbers of parallel build processes (i.e., the \u001b[1mmake\u001b[22m(1) \u001b[1m-j \u001b[22mflag).\r\n\r\n       This feature operates in conjunction with the  CFS  scheduler  and  re‐\r\n       quires  a  kernel that is configured with \u001b[1mCONFIG_SCHED_AUTOGROUP\u001b[22m.  On a\r\n       running system, this feature  is  enabled  or  disabled  via  the  file\r\n       \u001b[4m/proc/sys/kernel/sched_autogroup_enabled\u001b[24m;  a  value  of  0 disables the\r\n       feature, while a value of 1 enables it.  The default value in this file\r\n       is 1, unless the kernel was booted with the \u001b[4mnoautogroup\u001b[24m parameter.\r\n\r\n       A new autogroup is created when a new session is created via \u001b[1msetsid\u001b[22m(2);\r\n       this happens, for example, when a new terminal window  is  started.   A\r\n       new  process created by \u001b[1mfork\u001b[22m(2) inherits its parent's autogroup member‐\r\n       ship.  Thus, all of the processes in a session are members of the  same\r\n       autogroup.   An  autogroup  is  automatically  destroyed  when the last\r\n       process in the group terminates.\r\n\r\n       When autogrouping is enabled, all of the members of  an  autogroup  are\r\n       placed  in  the  same kernel scheduler \"task group\".  The CFS scheduler\r\n       employs an algorithm that equalizes  the  distribution  of  CPU  cycles\r\n       across  task groups.  The benefits of this for interactive desktop per‐\r\n       formance can be described via the following example.\r\n\r\n       Suppose that there are two autogroups competing for the same CPU (i.e.,\r\n       presume either a single CPU system or the use of \u001b[1mtaskset\u001b[22m(1) to  confine\r\n       all  the  processes to the same CPU on an SMP system).  The first group\r\n       contains ten CPU-bound processes  from  a  kernel  build  started  with\r\n       \u001b[4mmake\u001b[24m  \u001b[4m-j10\u001b[24m.   The  other  contains  a single CPU-bound process: a video\r\n       player.  The effect of autogrouping is that the two  groups  will  each\r\n       receive half of the CPU cycles.  That is, the video player will receive\r\n       50%  of  the CPU cycles, rather than just 9% of the cycles, which would\r\n       likely lead to degraded video playback.  The situation on an SMP system\r\n       is more complex, but the general effect is the same: the scheduler dis‐\r\n       tributes CPU cycles across task groups such that an autogroup that con‐\r\n       tains a large number of CPU-bound processes does not end up hogging CPU\r\n       cycles at the expense of the other jobs on the system.\r\n\r\n       A process's autogroup (task group) membership can  be  viewed  via  the\r\n       file \u001b[4m/proc/\u001b[24mpid\u001b[4m/autogroup\u001b[24m:\r\n\r\n           $ \u001b[1mcat /proc/1/autogroup\u001b[0m\r\n           /autogroup-1 nice 0\r\n\r\n       This  file can also be used to modify the CPU bandwidth allocated to an\r\n       autogroup.  This is done by writing a number in the \"nice\" range to the\r\n       file to set the autogroup's nice value.  The allowed range is from  +19\r\n       (low priority) to -20 (high priority).  (Writing values outside of this\r\n       range causes \u001b[1mwrite\u001b[22m(2) to fail with the error \u001b[1mEINVAL\u001b[22m.)\r\n\r\n       The  autogroup  nice  setting  has the same meaning as the process nice\r\n       value, but applies to distribution of CPU cycles to the autogroup as  a\r\n       whole,  based  on  the relative nice values of other autogroups.  For a\r\n       process inside an autogroup, the CPU cycles that it receives will be  a\r\n       product  of  the  autogroup's nice value (compared to other autogroups)\r\n       and the process's nice value (compared to other processes in  the  same\r\n       autogroup.\r\n\r\n       The  use of the \u001b[1mcgroups\u001b[22m(7) CPU controller to place processes in cgroups\r\n       other than the root CPU cgroup overrides the effect of autogrouping.\r\n\r\n       The autogroup feature groups only processes scheduled  under  non-real-\r\n       time  policies (\u001b[1mSCHED_OTHER\u001b[22m, \u001b[1mSCHED_BATCH\u001b[22m, and \u001b[1mSCHED_IDLE\u001b[22m).  It does not\r\n       group processes scheduled under real-time and deadline policies.  Those\r\n       processes are scheduled according to the rules described earlier.\r\n\r\n   \u001b[1mThe nice value and group scheduling\u001b[0m\r\n       When scheduling non-real-time processes (i.e.,  those  scheduled  under\r\n       the  \u001b[1mSCHED_OTHER\u001b[22m, \u001b[1mSCHED_BATCH\u001b[22m, and \u001b[1mSCHED_IDLE \u001b[22mpolicies), the CFS sched‐\r\n       uler employs a technique known as \"group scheduling\", if the kernel was\r\n       configured with the \u001b[1mCONFIG_FAIR_GROUP_SCHED \u001b[22moption (which is typical).\r\n\r\n       Under group scheduling, threads are scheduled in \"task  groups\".   Task\r\n       groups  have a hierarchical relationship, rooted under the initial task\r\n       group on the system, known as the \"root task group\".  Task  groups  are\r\n       formed in the following circumstances:\r\n\r\n       •  All of the threads in a CPU cgroup form a task group.  The parent of\r\n          this  task  group  is  the  task  group  of the corresponding parent\r\n          cgroup.\r\n\r\n       •  If autogrouping is enabled, then all of the threads  that  are  (im‐\r\n          plicitly) placed in an autogroup (i.e., the same session, as created\r\n          by \u001b[1msetsid\u001b[22m(2)) form a task group.  Each new autogroup is thus a sepa‐\r\n          rate  task group.  The root task group is the parent of all such au‐\r\n          togroups.\r\n\r\n       •  If autogrouping is enabled, then the root task group consists of all\r\n          processes in the root CPU cgroup that were not otherwise  implicitly\r\n          placed into a new autogroup.\r\n\r\n       •  If  autogrouping  is  disabled, then the root task group consists of\r\n          all processes in the root CPU cgroup.\r\n\r\n       •  If group scheduling was disabled (i.e., the  kernel  was  configured\r\n          without  \u001b[1mCONFIG_FAIR_GROUP_SCHED\u001b[22m),  then all of the processes on the\r\n          system are notionally placed in a single task group.\r\n\r\n       Under group scheduling, a thread's nice value has an effect for  sched‐\r\n       uling  decisions \u001b[4monly\u001b[24m \u001b[4mrelative\u001b[24m \u001b[4mto\u001b[24m \u001b[4mother\u001b[24m \u001b[4mthreads\u001b[24m \u001b[4min\u001b[24m \u001b[4mthe\u001b[24m \u001b[4msame\u001b[24m \u001b[4mtask\u001b[24m \u001b[4mgroup\u001b[24m.\r\n       This has some surprising consequences in terms of the  traditional  se‐\r\n       mantics  of  the  nice  value on UNIX systems.  In particular, if auto‐\r\n       grouping is enabled (which is the default  in  various  distributions),\r\n       then  employing  \u001b[1msetpriority\u001b[22m(2)  or  \u001b[1mnice\u001b[22m(1) on a process has an effect\r\n       only for scheduling relative to other processes executed  in  the  same\r\n       session (typically: the same terminal window).\r\n\r\n       Conversely, for two processes that are (for example) the sole CPU-bound\r\n       processes in different sessions (e.g., different terminal windows, each\r\n       of  whose  jobs  are  tied to different autogroups), \u001b[4mmodifying\u001b[24m \u001b[4mthe\u001b[24m \u001b[4mnice\u001b[0m\r\n       \u001b[4mvalue\u001b[24m \u001b[4mof\u001b[24m \u001b[4mthe\u001b[24m \u001b[4mprocess\u001b[24m \u001b[4min\u001b[24m \u001b[4mone\u001b[24m \u001b[4mof\u001b[24m \u001b[4mthe\u001b[24m \u001b[4msessions\u001b[24m \u001b[4mhas\u001b[24m \u001b[4mno\u001b[24m \u001b[4meffect\u001b[24m in  terms  of\r\n       the scheduler's decisions relative to the process in the other session.\r\n       A  possibly useful workaround here is to use a command such as the fol‐\r\n       lowing to modify the autogroup nice value for \u001b[4mall\u001b[24m of the processes in a\r\n       terminal session:\r\n\r\n           $ \u001b[1mecho 10 > /proc/self/autogroup\u001b[0m\r\n\r\n   \u001b[1mReal-time features in the mainline Linux kernel\u001b[0m\r\n       Since Linux 2.6.18, Linux is gradually becoming equipped with real-time\r\n       capabilities, most of which are derived from the  former  \u001b[4mrealtime-pre‐\u001b[0m\r\n       \u001b[4mempt\u001b[24m patch set.  Until the patches have been completely merged into the\r\n       mainline  kernel,  they must be installed to achieve the best real-time\r\n       performance.  These patches are named:\r\n\r\n           patch-\u001b[4mkernelversion\u001b[24m-rt\u001b[4mpatchversion\u001b[0m\r\n\r\n       and  can  be  downloaded  from   \u001b]8;;http://www.kernel.org/pub/linux/kernel/projects/rt/\u001b\\http://www.kernel.org/pub/linux/kernel\r\n       /projects/rt/\u001b]8;;\u001b\\.\r\n\r\n       Without the patches and prior to their full inclusion into the mainline\r\n       kernel,  the  kernel  configuration  offers  only  the three preemption\r\n       classes \u001b[1mCONFIG_PREEMPT_NONE\u001b[22m, \u001b[1mCONFIG_PREEMPT_VOLUNTARY\u001b[22m, and  \u001b[1mCONFIG_PRE‐\u001b[0m\r\n       \u001b[1mEMPT_DESKTOP  \u001b[22mwhich respectively provide no, some, and considerable re‐\r\n       duction of the worst-case scheduling latency.\r\n\r\n       With the patches applied or after their full inclusion into  the  main‐\r\n       line  kernel,  the  additional configuration item \u001b[1mCONFIG_PREEMPT_RT \u001b[22mbe‐\r\n       comes available.  If this is selected, Linux is transformed into a reg‐\r\n       ular real-time operating system.  The FIFO and RR  scheduling  policies\r\n       are  then used to run a thread with true real-time priority and a mini‐\r\n       mum worst-case scheduling latency.\r\n\r\n\u001b[1mNOTES\u001b[0m\r\n       The \u001b[1mcgroups\u001b[22m(7) CPU controller can be used to limit the CPU  consumption\r\n       of groups of processes.\r\n\r\n       Originally,  Standard Linux was intended as a general-purpose operating\r\n       system being able to handle background processes, interactive  applica‐\r\n       tions,  and  less  demanding  real-time applications (applications that\r\n       need to usually meet timing deadlines).  Although the Linux 2.6 allowed\r\n       for kernel preemption and the newly introduced O(1)  scheduler  ensures\r\n       that  the  time needed to schedule is fixed and deterministic irrespec‐\r\n       tive of the number of active tasks, true real-time  computing  was  not\r\n       possible up to Linux 2.6.17.\r\n\r\n\u001b[1mSEE ALSO\u001b[0m\r\n       \u001b[1mchcpu\u001b[22m(1), \u001b[1mchrt\u001b[22m(1), \u001b[1mlscpu\u001b[22m(1), \u001b[1mps\u001b[22m(1), \u001b[1mtaskset\u001b[22m(1), \u001b[1mtop\u001b[22m(1), \u001b[1mgetpriority\u001b[22m(2),\r\n       \u001b[1mmlock\u001b[22m(2), \u001b[1mmlockall\u001b[22m(2), \u001b[1mmunlock\u001b[22m(2), \u001b[1mmunlockall\u001b[22m(2), \u001b[1mnice\u001b[22m(2),\r\n       \u001b[1msched_get_priority_max\u001b[22m(2), \u001b[1msched_get_priority_min\u001b[22m(2),\r\n       \u001b[1msched_getaffinity\u001b[22m(2), \u001b[1msched_getparam\u001b[22m(2), \u001b[1msched_getscheduler\u001b[22m(2),\r\n       \u001b[1msched_rr_get_interval\u001b[22m(2), \u001b[1msched_setaffinity\u001b[22m(2), \u001b[1msched_setparam\u001b[22m(2),\r\n       \u001b[1msched_setscheduler\u001b[22m(2), \u001b[1msched_yield\u001b[22m(2), \u001b[1msetpriority\u001b[22m(2),\r\n       \u001b[1mpthread_getaffinity_np\u001b[22m(3), \u001b[1mpthread_getschedparam\u001b[22m(3),\r\n       \u001b[1mpthread_setaffinity_np\u001b[22m(3), \u001b[1msched_getcpu\u001b[22m(3), \u001b[1mcapabilities\u001b[22m(7), \u001b[1mcpuset\u001b[22m(7)\r\n\r\n       \u001b[4mProgramming\u001b[24m  \u001b[4mfor\u001b[24m  \u001b[4mthe\u001b[24m  \u001b[4mreal\u001b[24m  \u001b[4mworld\u001b[24m  \u001b[4m-\u001b[24m  \u001b[4mPOSIX.4\u001b[24m  by Bill O. Gallmeister,\r\n       O'Reilly & Associates, Inc., ISBN 1-56592-074-0.\r\n\r\n       The Linux kernel  source  files  \u001b[4mDocumentation/scheduler/sched-deadline\u001b[0m\r\n       \u001b[4m.txt\u001b[24m,     \u001b[4mDocumentation/scheduler/sched-rt-group.txt\u001b[24m,    \u001b[4mDocumentation/\u001b[0m\r\n       \u001b[4mscheduler/sched-design-CFS.txt\u001b[24m,      and       \u001b[4mDocumentation/scheduler/\u001b[0m\r\n       \u001b[4msched-nice-design.txt\u001b[0m\r\n\r\nLinux man-pages 6.7               2024-02-18                          \u001b[4msched\u001b[24m(7)\r\ntrantor@P7xxTM1:~$ "
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}